{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing loss/cost function\n",
    "1) MSE (mean_squared_error, 평균제곱오차)<br>\n",
    "2) RMSE (root_mean_squared_error, 평균제곱근편차)<br>\n",
    "3) RMSLE (root_mean_sqared_logarithmic_error)<br>\n",
    "4) CEE (cross_entropy_error, 교차엔트로피오차)<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1) MSE (mean_squared_error, 평균제곱오차)\n",
    "def MSE(y_p, y_t) : #y_p: predicted vector, y_t: actual_vector\n",
    "    return 0.5*np.sum((y_p - y_t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2) RMSE (root_mean_squared_error, 평균제곱근편차) : 예측값 벡터와 실제값 벡터의 유클리디언 거리\n",
    "def RMSE(y_p, y_t) : #y_p: predicted vector, y_t: actual_vector\n",
    "    return 0.5*(np.sum((y_p - y_t)**2)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3) RMSLE (root_mean_sqared_logarithmic_error) : 예측값 벡터와 실제값 벡터를 각각 log를 씌우고 유클리디언 거리를 구한다. \n",
    "                                                #RMSE에 비해서 커다란 오차의 페널티를 줄여준다.\n",
    "def RMSLE(y_p, y_t) : #y_p: predicted vector, y_t: actual_vector\n",
    "    return 0.5*np.sum(((np.log((y_p+1)/(y_t+1)))**2)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4) CEE (cross_entropy_error, 교차엔트로피오차)\n",
    "def CEE(y_p, y_t) : #y_p: predicted vector, y_t: actual_vector\n",
    "    if y.ndim == 1 : \n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    delta = 1e-7\n",
    "    return -1/y_p.shape[0]*np.sum(y_t*np.log(y_p + delta)) #y_p가 0이 되어 log 계산시 -inf가 나오는 현상 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEE (cross_entropy_error, 교차엔트로피오차)\n",
    "- 원핫으로 표현된 벡터의 경우, 즉 classification 문제의 경우 y_t의 값이 1개의 클래스(feature)를 제외하고는 0이다. 해당 클래스에 일치하는 경우의 에러만 카운트한다는 뜻이다.\n",
    "- 원핫이 아닌 경우는 말 그대로 해당 벡터의 엔트로피의 합을 구하는 식이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Differentiation & Gradient\n",
    "- 해석적 미분은 우리가 공부한 미분의 정의에 따라 미분을 전개한 것을 의미한다.\n",
    "- 수치미분은 실제 미분(해석적 미분)에 가장 가까운 값을 내도록 수치적으로 구현한 것을 의미한다. 이를테면 이어서 만든 numerical_diff() 함수가 바로 미분을 수치적으로 구현한 수치미분 함수이다.\n",
    "- 수치해석학은 이렇게 수학적 정의에 가까운 값을 내도록 수치적으로 최적화하여 구현하는 것을 의미한다.\n",
    "<br><br>\n",
    "1) numerical_diff (수치미분)<br>\n",
    "2) partial_diff (편미분)<br>\n",
    "3) numerical_gradient (경사 구하기(?))<br>\n",
    "4) gradient_descent (경사하강법)<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1) numerical_diff (수치미분)\n",
    "def numerical_diff(f, x) : #f: function(=f(x)), x: the point to get gradient\n",
    "    h = 1e-4 #0.0001\n",
    "    return (f(x+h)-f(x-h))/2*h #극한값을 표현하기 어려워서 h를 극단적으로 작은 값이 1e-4로 하여 중앙차분을 이용했다.\n",
    "                                #차분 : 함수값 A와 함수값 B의 차이, 여기선 f(x+h)-f(x-h)를 의미."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2) partial_diff (편미분)\n",
    "def partial_diff(f, x, n) : #f: fucntion(=f(x)) which takes multi variables, x: the input data array for function\n",
    "    h = 1e-4 #0.0001\n",
    "    temp = np.zeros_like(x)\n",
    "    temp[n] = temp[n] + h\n",
    "    xn_plus_h = temp\n",
    "    \n",
    "    temp[n] = temp[n] - 2*h\n",
    "    xn_minus_h = temp\n",
    "    \n",
    "    return (f(xn_plus_h)-f(xn_minus_h))/2*h #편미분은 함수 자체가 달라지진 않으며, input data인 x에서 집중할 xn을 제외한 다른 값들은 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3) numerical_gradient (경사 구하기(?))\n",
    "def numerical_gradient(f, x) : #편미분은 특정 변수에 대한 미분을 의미했는데, \n",
    "    #gradient는 각각의 변수에 대해 전부 편미분하여 그 값을 numpy array형태로 반환한다. 실제 내부 코드는 partial_diff와 크게 다르지 않다.\n",
    "    h = 1e-4 #0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(0, x.size) : \n",
    "        temp = x[idx]\n",
    "        \n",
    "        x[idx] = temp + h\n",
    "        fxh1 = f(x)\n",
    "        x[idx] = temp - h \n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1-fxh2)/(2*h)\n",
    "        x[idx] = temp\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4) gradient_descent (경사하강법)\n",
    "def gradient_descent(f, x, eta=0.01, epoch=100) : #eta: learning_rate, epoch: step_num (the number to iterate)\n",
    "\n",
    "    for i in range(epoch) : \n",
    "        grad = numerical_gradient(f, x) \n",
    "        x = x - eta*grad\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
