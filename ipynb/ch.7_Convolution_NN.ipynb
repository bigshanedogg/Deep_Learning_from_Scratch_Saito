{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Functions for spreading or packing tensors in lower dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1 #출력물의 높이\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1 #출력물의 너비\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 7, 7)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.random.rand(1,3,7,7)\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 75)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "col1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Classes implementing ReLU & Softmax layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReLU : \n",
    "    def __init__(self) : \n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x) : \n",
    "        self.mask = (x<=0) #numpy 배열 x와 같은 shape을 가진 배열을 만들고, 0 이상인 셀은 True, 0 미만인 셀은 False인 배열을 반환\n",
    "        out = x.copy() \n",
    "        out[self.mask] = 0 #numpy 배열인 x 중 0 이하인 값은 0으로 치환\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout) : \n",
    "        dout[self.mask] = 0 #numpy 배열 dout 중 0 이하인 값은 0으로 치환\n",
    "        dx = dout\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3-5) softmax_function\n",
    "def softmax_function(x) : \n",
    "    return np.exp(x-max(x))/np.sum(np.exp(x-max(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4-4) CEE (cross_entropy_error, 교차엔트로피오차)\n",
    "def CEE(y_p, y_t) : #y_p: predicted vector, y_t: actual_vector\n",
    "    if y.ndim == 1 : \n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    delta = 1e-7\n",
    "    return -1/y_p.shape[0]*np.sum(y_t*np.log(y_p + delta)) #y_p가 0이 되어 log 계산시 -inf가 나오는 현상 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SofwmaxWithLoss : \n",
    "    def __init__(self) : \n",
    "        self.loss = None #최종 결과물인 loss값\n",
    "        self.y = None #predicted Y\n",
    "        self.t = None #actual Y\n",
    "        \n",
    "    \n",
    "    def forward(self, x, t) : \n",
    "        self.t = t\n",
    "        self.y = softmax_function(x)\n",
    "        self.loss = CEE(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    \n",
    "    def backward(self, dout=1) : \n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Classes implementing Convolution & Pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Convolution : \n",
    "    def __init__(self, W, b, stride=1, pad=0) : \n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        \n",
    "    def forward(self, x) : \n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T \n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_W, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Pooling : \n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0) : \n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "    \n",
    "    \n",
    "    def forward(self, x) : \n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        #전개\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        \n",
    "        #max pooling\n",
    "        out = np.max(col, axis=1) \n",
    "        \n",
    "        #packing\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleConvNet : \n",
    "    def __init__(self, input_dim=(1,28,28), conv_param={\"filter_num\":30, \"filter_size\":5, \"pad\":0, \"stride\":1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01) : \n",
    "\n",
    "        #매개변수 설정\n",
    "        filter_num = conv_param[\"filter_num\"]\n",
    "        filter_size = conv_param[\"filter_size\"]\n",
    "        filter_pad = conv_param[\"pad\"]\n",
    "        filter_stride = conv_param[\"stride\"]\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "        \n",
    "        #각 레이어의 가중치 매개변수 설정\n",
    "        self.params = {}\n",
    "        self.params[\"W1\"] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params[\"b1\"] = np.zeros(filter_num)\n",
    "        self.params[\"W2\"] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params[\"b2\"] = np.zeros(hidden_size) \n",
    "        self.params[\"W3\"] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params[\"b3\"] = np.zeros(output_size) \n",
    "        \n",
    "        #각 레이어 초기화\n",
    "        self.layers = OrderDict()\n",
    "        self.layers[\"Conv1\"] = Convolution(self.params[\"W1\"], self.params[\"b1\"], conv_param[\"stride\"], conv_param[\"pad\"])\n",
    "        self.layers[\"ReLU1\"] = ReLU()\n",
    "        self.layers[\"Pool1\"] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers[\"Affine1\"] = Affine(self.params[\"W2\"], self.params[\"b2\"])\n",
    "        self.layers[\"ReLU2\"] = ReLU()\n",
    "        self.layers[\"Affine2\"] = Affine(self.params[\"W3\"], self.params[\"b3\"])\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "    \n",
    "    def predict(self, x) : \n",
    "        for layer in self.layers.values() : \n",
    "            x = layer.forward(x)            \n",
    "        return x \n",
    "    \n",
    "    \n",
    "    def loss(self, x, y) : \n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "    \n",
    "    \n",
    "    def gradient(self, x, t) : \n",
    "        #순전파 (순전파하면서 가중치 매개변수들 갱신)\n",
    "        self.loss(x, t) \n",
    "        \n",
    "        #역전파\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers :\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        #결과 저장\n",
    "        grads = {}\n",
    "        grads[\"W1\"] = self.layers[\"Conv1\"].dW\n",
    "        grads[\"b1\"] = self.layers[\"Conv1\"].db\n",
    "        grads[\"W2\"] = self.layers[\"Affine1\"].dW\n",
    "        grads[\"b2\"] = self.layers[\"Affine1\"].db\n",
    "        grads[\"W3\"] = self.layers[\"Affine2\"].dW\n",
    "        grads[\"b3\"] = self.layers[\"Affine2\"].db\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
