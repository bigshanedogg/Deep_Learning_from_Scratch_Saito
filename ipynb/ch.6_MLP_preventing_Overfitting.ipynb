{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys, os\n",
    "sys.path.append(os.pardir) \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Required Classes & Functions to make Two-Layer Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReLU : \n",
    "    def __init__(self) : \n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x) : \n",
    "        self.mask = (x<=0) #numpy 배열 x와 같은 shape을 가진 배열을 만들고, 0 이상인 셀은 True, 0 미만인 셀은 False인 배열을 반환\n",
    "        out = x.copy() \n",
    "        out[self.mask] = 0 #numpy 배열인 x 중 0 이하인 값은 0으로 치환\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout) : \n",
    "        dout[self.mask] = 0 #numpy 배열 dout 중 0 이하인 값은 0으로 치환\n",
    "        dx = dout\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Affine : \n",
    "    def __init__(self, W, b) : \n",
    "        self.W = W \n",
    "        self.b = b \n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "    \n",
    "    def forward(self, x) : \n",
    "        self.x = x \n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def backward(self, dout) : \n",
    "        dx = np.dot(dout, self.W.T) \n",
    "        self.dW = np.dot(self.x.T, dout) \n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#softmax_function\n",
    "def softmax_function(x) : \n",
    "    max_by_row = np.amax(x, axis=1)\n",
    "    max_by_row = np.reshape(max_by_row, [max_by_row.shape[0],1])\n",
    "    nom = np.exp(x-max_by_row)\n",
    "    denom = np.sum(np.exp(x-max_by_row), axis=1)\n",
    "    denom = np.reshape(denom, [denom.shape[0],1])\n",
    "    return nom/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mini_batch(x, y, i, batch_size) : \n",
    "    if i+batch_size >= len(x) :\n",
    "        x_batch = x[i*batch_size:len(x)] #마지막 부분은 예외처리 (list index range)\n",
    "        y_batch = y[i*batch_size:len(y)]\n",
    "    else : \n",
    "        x_batch = x[i*batch_size:(i+1)*batch_size] \n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size] \n",
    "    \n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CEE (cross_entropy_error, 교차엔트로피오차)\n",
    "def CEE(y_p, y_t) : #y_p: predicted vector, y_t: actual_vector\n",
    "    if y_t.ndim == 1 : \n",
    "        y_t = y_t.reshape(1, y_t.size)\n",
    "        y_p = y_p.reshape(1, y_p.size)\n",
    "        \n",
    "    delta = 1e-7\n",
    "    return -1/y_p.shape[0]*np.sum(y_t*np.log(y_p + delta)) #y_p가 0이 되어 log 계산시 -inf가 나오는 현상 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_numerical_gradient(f, x) : #편미분은 특정 변수에 대한 미분을 의미했는데, \n",
    "    #gradient는 각각의 변수에 대해 전부 편미분하여 그 값을 numpy array형태로 반환한다. 실제 내부 코드는 partial_diff와 크게 다르지 않다.\n",
    "    h = 1e-4 #0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    for i in range(0, x.shape[0]) : \n",
    "        for j in range(0, x.shape[1]) : \n",
    "            temp = x[i][j]\n",
    "\n",
    "            x[i][j] = temp + h\n",
    "            fxh1 = f(x[i][j])\n",
    "            x[i][j] = temp - h \n",
    "            fxh2 = f(x[i][j])\n",
    "\n",
    "            grad[i][j] = (fxh1-fxh2)/(2*h)\n",
    "            x[i][j] = temp\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ㅜnumerical differentian function for bias (수치 미분 함수)\n",
    "def bias_numerical_gradient(f, x) : #편미분은 특정 변수에 대한 미분을 의미했는데, \n",
    "    #gradient는 각각의 변수에 대해 전부 편미분하여 그 값을 numpy array형태로 반환한다. 실제 내부 코드는 partial_diff와 크게 다르지 않다.\n",
    "    h = 1e-4 #0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    for i in range(0, x.shape[0]) : \n",
    "        temp = x[i]\n",
    "\n",
    "        x[i] = temp + h\n",
    "        fxh1 = f(x[i])\n",
    "        x[i] = temp - h \n",
    "        fxh2 = f(x[i])\n",
    "\n",
    "        grad[i] = (fxh1-fxh2)/(2*h)\n",
    "        x[i] = temp\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss : \n",
    "    def __init__(self) : \n",
    "        self.loss = None #최종 결과물인 loss값\n",
    "        self.y = None #predicted Y\n",
    "        self.t = None #actual Y\n",
    "        \n",
    "    \n",
    "    def forward(self, x, t) : \n",
    "        self.t = t\n",
    "        self.y = softmax_function(x)\n",
    "        self.loss = CEE(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    \n",
    "    def backward(self, dout=1) : \n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SGD :\n",
    "    def __init__(self, lr=0.01) : \n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, params, grads) : \n",
    "        for key in params.keys() : \n",
    "            params[key] -= self.lr * grads[key]\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Momentum : \n",
    "    def __init__(self, lr=0.01, momentum=0.9) : #momentum means 'alpha' which controll v's ratio to pass next epoch\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads) : \n",
    "        if self.v is None : \n",
    "            self.v = {}\n",
    "            for key, val in params.items() : \n",
    "                self.v[key] = np.zeros_like(val) \n",
    "        \n",
    "        for key in params.keys() : \n",
    "            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
    "            params[key] += self.v[key]\n",
    "            \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdaGrad : \n",
    "    def __init__(self, lr=0.01) : \n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "        \n",
    "    def update(self, params, grads) : \n",
    "        if self.h is None : \n",
    "            self.h = {}\n",
    "            for key, val in params.items() : \n",
    "                self.h[key] = np.zeros_like(val) \n",
    "                \n",
    "        for key in params.keys() : \n",
    "            self.h[key] += grads[key] * grads[key]\n",
    "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n",
    "            \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = {}, {}\n",
    "            for key, val in params.items():\n",
    "                self.m[key] = np.zeros_like(val)\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "        \n",
    "        self.iter += 1\n",
    "        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         \n",
    "        \n",
    "        for key in params.keys():\n",
    "            #self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]\n",
    "            #self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)\n",
    "            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n",
    "            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])\n",
    "            \n",
    "            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)\n",
    "            \n",
    "            #unbias_m += (1 - self.beta1) * (grads[key] - self.m[key]) # correct bias\n",
    "            #unbisa_b += (1 - self.beta2) * (grads[key]*grads[key] - self.v[key]) # correct bias\n",
    "            #params[key] += self.lr * unbias_m / (np.sqrt(unbisa_b) + 1e-7)\n",
    "            \n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Two-Layer Neural Net extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet : \n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01) : \n",
    "        self.weight_decay_flag = None\n",
    "        #weight initialization \n",
    "        self.params = {}\n",
    "        self.params[\"W1\"] = weight_init_std * np.random.randn(input_size, hidden_size) #random.randn은 음수 포함한 랜덤 실수 생성\n",
    "        self.params[\"b1\"] = np.zeros(hidden_size) \n",
    "        self.params[\"W2\"] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params[\"b2\"] = np.zeros(output_size)\n",
    "        \n",
    "        #Layers \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers[\"Affine1\"] = Affine(self.params[\"W1\"], self.params[\"b1\"])\n",
    "        self.layers[\"ReLU1\"] = ReLU()\n",
    "        self.layers[\"Affine2\"] = Affine(self.params[\"W2\"], self.params[\"b2\"]) \n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "\n",
    "    \n",
    "    def set_train_flag(self, train_flag=True) : \n",
    "        self.train_flag = train_flag\n",
    "    \n",
    "    def set_flag(self, weight_decay=False, drop_out=False) : \n",
    "        self.weight_decay_flag = weight_decay\n",
    "        self.dropout_flag = drop_out\n",
    "        if self.dropout_flag :\n",
    "            self.dlayers = OrderedDict()\n",
    "            self.dlayers[\"Affine1\"] = Affine(self.params[\"W1\"], self.params[\"b1\"])\n",
    "            self.dlayers[\"Dropout1\"] = Dropout()\n",
    "            self.dlayers[\"ReLU1\"] = ReLU()\n",
    "            self.dlayers[\"Affine2\"] = Affine(self.params[\"W2\"], self.params[\"b2\"]) \n",
    "            self.dlayers[\"Dropout2\"] = Dropout()\n",
    "        \n",
    "        \n",
    "    def predict(self, x) : \n",
    "        if self.dropout_flag : \n",
    "            for layer in self.dlayers.values() : \n",
    "                try : \n",
    "                    if self.train_flag : \n",
    "                        x = layer.train_forward(x)\n",
    "                    else : \n",
    "                        x = layer.test_forward(x)\n",
    "                except : \n",
    "                    x = layer.forward(x)\n",
    "        else : \n",
    "            for layer in self.layers.values() : \n",
    "                x = layer.forward(x)\n",
    "                \n",
    "        return x\n",
    "    \n",
    "    #weight decay\n",
    "    def weight_decay(self) : \n",
    "        lb = 0.5\n",
    "        self.decay = 0\n",
    "        for key in self.params.keys() : \n",
    "            self.decay += 0.5 * lb * np.sum((self.params[key] * self.params[key]))\n",
    "            \n",
    "    \n",
    "    #x: input_data, t: label\n",
    "    def loss(self, x, t) : \n",
    "        y = self.predict(x) \n",
    "        loss_value = self.lastLayer.forward(y, t)\n",
    "        \n",
    "        if self.weight_decay_flag : \n",
    "            self.weight_decay()\n",
    "            return (loss_value+self.decay)\n",
    "        else : \n",
    "            return loss_value\n",
    "    \n",
    "    \n",
    "    #x: input_data, t: label\n",
    "    def accuracy(self, x, t) : \n",
    "        y = self.predict(x) \n",
    "        y = np.argmax(y, axis=1) \n",
    "        if t.ndim != 1 : #1d vector가 아니라 one-hot된 2d matrix라면 argmax를 이용해 1d vector로 변환한다.\n",
    "            t = np.argmax(t, axis=1)\n",
    "            \n",
    "        accuracy = np.sum(y==t) / float(x.shape[0]) # 평균 오차 = (y_t - y_p)/batch_size\n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    #x: input_data, t: label\n",
    "    def numerical_gradient(self, x, t) : \n",
    "        loss_W = lambda W: self.loss(x, t) \n",
    "        \n",
    "        grads = {}\n",
    "        grads[\"W1\"] = weight_numerical_gradient(loss_W, self.params[\"W1\"])\n",
    "        grads[\"b1\"] = bias_numerical_gradient(loss_W, self.params[\"b1\"])\n",
    "        grads[\"W2\"] = weight_numerical_gradient(loss_W, self.params[\"W2\"])\n",
    "        grads[\"b2\"] = bias_numerical_gradient(loss_W, self.params[\"b2\"])\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    \n",
    "    def gradient(self, x, t) : \n",
    "        #forward propagation\n",
    "        self.loss(x, t) \n",
    "        \n",
    "        #backward propagation\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        \n",
    "        if self.dropout_flag : \n",
    "            dlayers = list(self.dlayers.values())\n",
    "            dlayers.reverse()\n",
    "            for layer in dlayers : \n",
    "                dout = layer.backward(dout)\n",
    "        else : \n",
    "            layers = list(self.layers.values())\n",
    "            layers.reverse()\n",
    "            for layer in layers : \n",
    "                dout = layer.backward(dout)\n",
    "\n",
    "        #save result\n",
    "        grads = {}\n",
    "        #self.layers.values()를 forward & backward하면서 클래스 변수인 dW와 db가 없데이트되었다.\n",
    "        grads[\"W1\"] = self.layers[\"Affine1\"].dW \n",
    "        grads[\"b1\"] = self.layers[\"Affine1\"].db\n",
    "        grads[\"W2\"] = self.layers[\"Affine2\"].dW\n",
    "        grads[\"b2\"] = self.layers[\"Affine2\"].db\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mnist 데이터 pickle로 로드\n",
    "temp = []\n",
    "\n",
    "with open(\"mnist_dataset.txt\", mode=\"rb\") as fp : \n",
    "    temp = pickle.load(fp)\n",
    "    temp[0] = np.reshape(temp[0], [temp[0].shape[0], -1])\n",
    "    temp[2] = np.reshape(temp[2], [temp[2].shape[0], -1])\n",
    "    \n",
    "    nb_classes = 10\n",
    "    temp[1] = np.array([temp[1]]).reshape(-1)\n",
    "    temp[1] = np.eye(nb_classes)[temp[1]]\n",
    "    temp[3] = np.array([temp[3]]).reshape(-1)\n",
    "    temp[3] = np.eye(nb_classes)[temp[3]]\n",
    "    \n",
    "x_train, y_train, x_test, y_test = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2) Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = TwoLayerNet(input_size=x_train.shape[1], hidden_size=50, output_size=10)\n",
    "optimizer = SGD()\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "for i in range(1000) : \n",
    "    x_batch, t_batch = get_mini_batch(x_train, y_train, i, batch_size)\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    params = network.params\n",
    "    network.params = optimizer.update(params, grads)\n",
    "    accuracy_list.append(network.accuracy(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X2QFfWd7/H3lxlAHuRJWIPACio+4EMgDqwWNybrVYPm\nrlIbE3SvCa5UyF5j1BiNGrOmLspWNty6uG5ZLm5WTYhXNLLeUBECXh+21nJFxmhQQBTRxUEU1AGM\n4DAP3/vH6T70nDlnzsOch57Tn1fVFKd/p7vn1/Sc/pzf79cP5u6IiIgMqHUFREQkHhQIIiICKBBE\nRCSgQBAREUCBICIiAQWCiIgACgQREQkoEEREBFAgiIhIoLHWFSjG2LFjffLkybWuhohIv/LSSy99\n6O7j8s3XrwJh8uTJNDc317oaIiL9ipn9ZyHzqctIREQABYKIiAQUCCIiAigQREQkoEAQERFAgSAi\nIgEFgoiIAAkKhBUrVrB3795aV0NEJLYSEQhbtmzh8ssv58orr6x1VUREYisRgXDgwAEAduzYUeOa\niIjEVyICwcxqXQURkdhLVCC4e41rIiISXwoEEREBEhIIIQWCiEhuiQgEjSGIiOSXiEAIqYUgIpJb\nIgJBYwgiIvklKhBERCS3RARCSC0EEZHcCgoEM5tjZlvNbJuZ3ZLl/RvMbLOZbTSzp8zs2KD8z83s\nlcjPZ2Y2N3jvQTN7O/Le9PJuWrf6VWrVIiJ1ozHfDGbWANwDnA+0ABvMbJW7b47M9jLQ5O4HzOx/\nAD8D5rn7M8D0YD1jgG3AushyN7n7Y+XZlPzUQhARya2QFsIsYJu7b3f3Q8AK4JLoDO7+jLsfCCZf\nACZmWc+lwJrIfFWjFoKISH6FBMIE4N3IdEtQlssCYE2W8suAhzPKFgfdTEvNbHABdekTtRBERHIr\n66CymV0BNAFLMsrHA6cDayPFtwInAzOBMcDNOda50Myazax5z549pdarpOVERJKkkEDYCUyKTE8M\nyroxs/OA24CL3b0t4+1vAI+7e3tY4O67PKUNeIBU11QP7n6fuze5e9O4ceMKqG5uaiGIiORWSCBs\nAKaa2RQzG0Sq62dVdAYzmwEsIxUGu7Os43IyuouCVgOW+vo+F3it+OoXRhemiYjkl/csI3fvMLNr\nSHX3NAD3u/smM1sENLv7KlJdRMOBXwcH3x3ufjGAmU0m1cL4t4xVP2Rm4wADXgH+pixblIUCQUQk\nv7yBAODuq4HVGWW3R16f18uy75BlENrdzy24ln2kQBARyS8RVyprUFlEJL9EBEJILQQRkdwSEQhq\nIYiI5JeIQAiphSAikluiAkFERHJLVCCohSAiklsiAkFBICKSXyICIaRgEBHJTYEgIiJAQgJBQSAi\nkl8iAiGkYBARyS0RgaAgEBHJLxGBEFIwiIjklohACINAgSAiklsiAiGkQBARyS0RgaAgEBHJLxGB\nEFIwiIjkVlAgmNkcM9tqZtvM7JYs799gZpvNbKOZPWVmx0be6zSzV4KfVZHyKWa2PljnI8HzmitK\ngSAiklveQDCzBuAe4EJgGnC5mU3LmO1loMndzwAeA34Wee+gu08Pfi6OlP89sNTdTwBagQV92I5e\nKQhERPIrpIUwC9jm7tvd/RCwArgkOoO7P+PuB4LJF4CJva3QUk+sOZdUeAD8AphbTMVLoWAQEcmt\nkECYALwbmW4JynJZAKyJTB9hZs1m9oKZhQf9o4C97t6Rb51mtjBYvnnPnj0FVLcnBYGISH6N5VyZ\nmV0BNAFfihQf6+47zew44GkzexXYV+g63f0+4D6ApqamPh3ZFQwiIrkV0kLYCUyKTE8Myroxs/OA\n24CL3b0tLHf3ncG/24FngRnAR8AoMwsDKes6y0VBICKSXyGBsAGYGpwVNAi4DFgVncHMZgDLSIXB\n7kj5aDMbHLweC8wGNnvqCP0McGkw63zgN33dmHwUDCIiueUNhKCf/xpgLbAFeNTdN5nZIjMLzxpa\nAgwHfp1xeukpQLOZ/YFUAPzU3TcH790M3GBm20iNKfxL2baq5zZUatUiInWjoDEEd18NrM4ouz3y\n+rwcyz0PnJ7jve2kzmCqGgWDiEhuulJZRESAhASC7nYqIpJfIgIhpEAQEcktEYGgIBARyS8RgRBS\nMIiI5JaIQFAQiIjkl4hACCkYRERyS0QgZAbBiy++yLx58+js7KxRjURE4icRgRAKg+FrX/sajz76\nKO+9916NayQiEh+JCAR1FYmI5JeIQAjpAjURkdwSGQih1IPbREQEEhIIahGIiOSXiEAIKRhERHJL\nRCBkjh0oGEREekpEIIQ0hiAikltBgWBmc8xsq5ltM7Nbsrx/g5ltNrONZvaUmR0blE83s/8ws03B\ne/MiyzxoZm8HT1h7xcyml2+zulOLQEQkv7yBYGYNwD3AhcA04HIzm5Yx28tAk7ufATwG/CwoPwB8\ny91PBeYAd5nZqMhyN7n79ODnlT5uS14KBhGR3AppIcwCtrn7dnc/BKwALonO4O7PuPuBYPIFYGJQ\n/oa7vxm8fg/YDYwrV+ULlRkECgYRkZ4KCYQJwLuR6ZagLJcFwJrMQjObBQwC3ooULw66kpaa2eAC\n6tInGkMQEcmtrIPKZnYF0AQsySgfDywH/trdu4LiW4GTgZnAGODmHOtcaGbNZta8Z8+ePtVPLQUR\nkdwKCYSdwKTI9MSgrBszOw+4DbjY3dsi5SOAJ4Db3P2FsNzdd3lKG/AAqa6pHtz9PndvcvemceNK\n623SgV9EJL9CAmEDMNXMppjZIOAyYFV0BjObASwjFQa7I+WDgMeBX7r7YxnLjA/+NWAu8FpfNqQQ\n6jISEcmtMd8M7t5hZtcAa4EG4H5332Rmi4Bmd19FqotoOPDr4CC7w90vBr4BnAMcZWZXBqu8Mjij\n6CEzGwcY8ArwN+XdtG7bUKlVi4jUjbyBAODuq4HVGWW3R16fl2O5XwG/yvHeuYVXszwUDCIiuSXi\nSmUNJouI5JeIQAhpDEFEJLdEBIJaBCIi+SUiEELqOhIRyS2RgaAgEBHpKRGBkCsIkhIMq1atYsyY\nMRw8eLDWVRGRGEtEIISSGgg/+MEPaG1tpaWlpdZVEZEYS0QgJOXAn0tHRwcADQ0NNa6JiMRZIgIh\nlNQWQhgIjY0FXYcoIgmViEBIahCEwkAYOHBgjWsiInGWiEDIJSnBEAaCLsQTkd4kIhCiB/7W1lZ2\n797dy9z1p7OzE0hOAIpIaRIRCFHf+c530q+TcoAMWwhJ2V4RKU0iAiF6IPzggw9qWJPa+OSTTwAF\ngoj0LhGBENXWln6YWyIOkAcOHEi/TsL2ikjpEh0ISRB2F4ECQUR6l4hAiB4Ik9ZCCAeUIRnbKyKl\nKygQzGyOmW01s21mdkuW928ws81mttHMnjKzYyPvzTezN4Of+ZHyM83s1WCdd1uVzolMWgtBgSAi\nhcobCGbWANwDXAhMAy43s2kZs70MNLn7GcBjwM+CZccAPwH+DJgF/MTMRgfL3At8G5ga/Mzp89bk\n0JcWQldXF5999llF6lUN6jISkUIV0kKYBWxz9+3ufghYAVwSncHdn3H3cPTyBWBi8PorwJPu/rG7\ntwJPAnPMbDwwwt1f8NRR6pfA3DJsT16HDh2K1jvv/DfeeCNDhgzptlx/smrVqvRrBYKI9KaQQJgA\nvBuZbgnKclkArMmz7ITgdd51mtlCM2s2s+Y9e/YUUN2ecrUQCvHP//zPJS0XF0m87kJESlPWQWUz\nuwJoApaUa53ufp+7N7l707hx4/q8vmK7jOrpIFpP2yIi5VdIIOwEJkWmJwZl3ZjZecBtwMXu3pZn\n2Z0c7lbKuc5yiR4Io33qxaiH+wApEESkN4UEwgZgqplNMbNBwGXAqugMZjYDWEYqDKI3CloLXGBm\no4PB5AuAte6+C9hvZmcFZxd9C/hNGbYnr66urvRrtRBERA7Le4N8d+8ws2tIHdwbgPvdfZOZLQKa\n3X0VqS6i4cCvg2/SO9z9Ynf/2MzuIBUqAIvc/ePg9dXAg8AQUmMOa6iCJB8Uk7ztIpJfQU9McffV\nwOqMstsjr8/rZdn7gfuzlDcDpxVc0z7IdSAs5gBZDwfTetgGEamcRFyp3BfhQbRcB9MlS5bw8ssv\nl2VdIiLllIhnKsaphfDDH/6wrOsrRlxbCJ2dnbS1tTF06NBaV0Uk0dRCyKOcLYSWlpb8M1VQXANh\nwYIFDBs2rNbVEEm8RARCXFoIJ554Yp/X0RdxDYRf/OIXta6CiJCQQMil2oFw8ODBPq+jL+IYCNHT\ngEWkthIRCH05EJZ7ULmW4rgNP/rRj9Kv41g/kSRJRCDkkusA1NzczBtvvFHQvP1JHLfh0UcfTb+O\nY/1EkiQRZxkVa+bMmUD3A1Q9HKziuA3R5zV0dXUxYECiv6OI1FQiPn19GVRWl1FlFXsrERGpnEQE\nQjn014PV5z//+fTrOG6DAkEkPhIRCEluIUTP74/jNmR2GYlI7SQiEMohjgfTQsT9G3jc6yeSJIkI\nhLhcmFYLcT/gqoUgEh+JCIS+qESXUTUfttOfAiGO9RNJkkQEQlJbCI8//jjNzc3p6ThuQ9wDSyRJ\nEhEId9xxR8nLVqKFUK0D31/+5V8C0NDQUNXfWwx1GYnER0GBYGZzzGyrmW0zs1uyvH+Omf3ezDrM\n7NJI+Z+b2SuRn8/MbG7w3oNm9nbkvenl26zuXnzxxazl+Q6Q7733XsHzxlmcA0EtBJH4yHulspk1\nAPcA5wMtwAYzW+XumyOz7QCuBG6MLuvuzwDTg/WMAbYB6yKz3OTuj/VlA/oi3wFowoQJsT6YFirc\nhjhSC0EkPgq5dcUsYJu7bwcwsxXAJUA6ENz9neC93j7RlwJr3P1AybWtgf5+HQKQvh1EHLdBg8oi\n8VFIl9EE4N3IdEtQVqzLgIczyhab2UYzW2pmg0tYZ5/kOgBl+0bdnw9WcW7lRFsFaiGI1FZVBpXN\nbDxwOrA2UnwrcDIwExgD3Jxj2YVm1mxmzXv27Cn19xc1//Dhw3uUxfFgWqg4B0JU3OsnUu8KCYSd\nwKTI9MSgrBjfAB539/awwN13eUob8ACprqke3P0+d29y96Zx48YV+WtTcgVCrgNQ9Nm+9dBlpEAQ\nkUIUEggbgKlmNsXMBpHq+llV5O+5nIzuoqDVgKWO1nOB14pcZ1X15+6M/hII/fn/WKQe5A0Ed+8A\nriHV3bMFeNTdN5nZIjO7GMDMZppZC/B1YJmZbQqXN7PJpFoY/5ax6ofM7FXgVWAscGffNye7YlsI\n2crjfjDtTVwDoa2trdt03OonkjQFPSDH3VcDqzPKbo+83kCqKynbsu+QZRDa3c8tpqJ9UewYQnhg\nGj16NHv37u1W1h/FNRAOHTrUbVotBJHaSsSVysW2EMIDU708MS2ugdDR0dFtOm71E0maRARCscID\nU1dXlwaVK0iBIBIviQiEXM/pzTeGoBZCZWUGgrqMRGorEYFQ6qCyAqGy1EIQiZdEBEKxsgXCNddc\nw5o1a2pVpT7pL4GgFoJIbSUiEEodVI4eoJ599lkuuuii8leuCvpLIMStfrVw4MAB5s2bx86dxV77\nKdJ3BZ122t+VetppvRygFAj9x8qVK3n00UcZNGgQy5cvr3V1JGHUQuilvD8foKJ17y+BoC4jkdpK\nRCAUK3raaX8VPfg3Njb2KIsDtRBE4iURgZDEFkI0zAYOHFjDmuSmFoJIvCQ6EHKpt0BQC0FECpHo\nQCjm1hX9jQJBRIqViEAoVj2MIWTrMorbAVddRiLxkohAKPXWFZUycWLWG8OWlVoIIlKsRARCqWMI\n5Xb22Wd3+7eS+lML4Wtf+xqgFgLEbx9JsiQiEHKpdguhmmMT/amFMG3aNCB+9RNJmkQEQqmDyuVW\nzbOX+lMLYdCgQUD86ieSNAUFgpnNMbOtZrbNzG7J8v45ZvZ7M+sws0sz3us0s1eCn1WR8ilmtj5Y\n5yPB85oropQuo2KXKXS90X8rqT8EQnNzM3C4fuoyEqmtvIFgZg3APcCFwDTgcjObljHbDuBK4P9k\nWcVBd58e/FwcKf97YKm7nwC0AgtKqH9BSrkwLbzdQzmpy6i77du3AzBlyhQgfvUTSZpCWgizgG3u\nvt3dDwErgEuiM7j7O+6+ESjoK56ljtDnAo8FRb8A5hZc6yrIdWZSX6iF0F17ezvTpk3jyCOPBNRC\nEKm1Qo56E4B3I9MtQVmhjjCzZjN7wczCg/5RwF53D887zLlOM1sYLN+8Z8+eIn5tt3VkLc92gAzL\n6ikQwhZCe3t7xX9vMTo6Ohg4cGB6/8QtsAT+8Ic/8I//+I+1rkaiPP/889x///01+d3VGFQ+1t2b\ngL8C7jKz44tZ2N3vc/cmd28aN25cSRUoZjwgPJDWU5dR2EKYN29exX9vMdrb22lsbEyHrwIhfqZP\nn861115b62okyuzZs1mwoGI96L0qJBB2ApMi0xODsoK4+87g3+3As8AM4CNglJmFz2Moap3FKqWF\nUIlAqHULIW4yWwjqMhKprUICYQMwNTgraBBwGbAqzzIAmNloMxscvB4LzAY2e+qI+AwQnpE0H/hN\nsZUvVDEthEp2GZW7hfDpp59y8ODBXn8XxPdup2oh5FaJs9xE8sl71Av6+a8B1gJbgEfdfZOZLTKz\niwHMbKaZtQBfB5aZ2aZg8VOAZjP7A6kA+Km7bw7euxm4wcy2kRpT+JdyblhUvY4hDB8+nM997nNZ\n3+sPgaAWgki8FNSX4O6rgdUZZbdHXm8g1e2TudzzwOk51rmd1BlMFVdKC6G/dBnt378/a3l/6DJq\nb2/niCOO0KCySEwk4krlXLIdgMIDaX/oMirkd0F8AyFsIajLKP60b5IhEYFQSpdRJWhQubtwDEFd\nRvGnfZMMiQ6EbKoRCNUQvbV03McQ1ELoKW7/FwqEZEh0IPTWQqjEB7KaXUbRs4/iGghqIfQf2jfJ\nkIhAKEYlA6GaXUaffvopAGeddVZVnr9QCl2p3H9o3yRDIgKhmCem1csYwoEDBwC46667OOKIIyr+\n+0qh6xD6j3pqITzyyCOMHj2akSNHMnLkSI4++mheeeWVWlerh1p8HhIRCKXcuqISqtllFLYQhg0b\nRmdnZ8V/Xyl0HUJucbswrZ72zcsvv8z+/fu56qqrmDt3Lrt372br1q21rlYPtfg/T0Qg5FLKGMLz\nzz/f599X7UDIfHZxXGS2EOrpoFNv6mnfdHZ2MnjwYJYuXcqPfvSjdFnc1KJOiQiEcp5lNHv2bN57\n772S6lGLLqOhQ4fGMhDcnQ8//JCBAwemLwKM44dSUuotEMK/uTj/7SkQKqTcZxn98Y9/LKketegy\nimsgrF+/Hkh1G8X5Qykp9TS+Ew2E8BqdOH5G1GVUIeW+DqHU/t1qthDa2toAOOKII2L5xx62subP\nn5/+UCoQ4nvgVQuh+tRCqLLebl1RiQ9muIOr8aEPH4bT2NjIqFGjKv77itXa2grA5z73ufSHMo7B\nVW0KhMpTIOQWz3salFlcbl1RzS6j6EVfp5xyCpMnT47VE9PCQBg9enS6NRPHD2W1KRAqr78EgrqM\nKqSULqM4txC2bduWdx2HDh3qdoXyOeecE6t7Gu3du5eGhgaGDx8e6w9ltcX1wBvXepWivwSCuowq\npNwthHwfjj/+8Y+YWY9n0ZYjENatW8fUqVNZsWJFr/O1t7czaNCg9HRDQ0Os/ug/+eQTjjzySMws\n1h/KaovrgTeuLZdSKBByS3QgZFPIH36+HbVr1y4A7r777m7l5egyam5uBlIPP+9Ne3t7txZC3ALh\n4MGDDBkyBIj3mR7VFtcDb1yDqhT95Syj2AaCmc0xs61mts3Mbsny/jlm9nsz6zCzSyPl083sP8xs\nk5ltNLN5kfceNLO3zeyV4Gd6eTYpa/2zlvc2qNybfDsqfD/zlhnlaCF89tlnAHlvR5EtEOL0of7s\ns8/S2xDnb2nVFqd9FBXXepUieqpznP/2avF/nrdT2cwagHuA84EWYIOZrYo8ChNgB3AlcGPG4geA\nb7n7m2Z2DPCSma11973B+ze5+2N93Yh8yj2GUGggfPbZZ7S1tTF48OBu5bUIhAEDBsTqj16BkJ1a\nCJWnLqPcCmkhzAK2uft2dz8ErAAuic7g7u+4+0agK6P8DXd/M3j9HrAbGFeWmpdBqRemFRoIO3bs\n4Mwzz0yXl6PLKAyEsLsll7h3GSkQsovrgTeu9SqFAiG3QgJhAvBuZLolKCuKmc0CBgFvRYoXB11J\nS81scLHrLOJ3d5u+8cbMhsxhuQ7W8+ale7vy7qjoh2fTpk0FL5fPyy+/nB6ojg4YZ6Muo/4pri2E\nuNarFAqE3KoyqGxm44HlwF+7e3hUuhU4GZgJjAFuzrHsQjNrNrPmPXv2lPr7u01fcMEFQOEthMWL\nF3PMMcekp/MNQOV6v69dRuvWreuxrlz6U5dRnAf2qi1OoR0V13qVIhoIZha7z0Yortch7AQmRaYn\nBmUFMbMRwBPAbe7+Qlju7rs8pQ14gFTXVA/ufp+7N7l707hxpfU2ZQZCb08Qy9at09DQkP4DgsIO\nxpmi6ys1EMIb1sHhW1PkknkdgrqM+oe4fhOv10CA+H02QnG9UnkDMNXMppAKgsuAvypk5WY2CHgc\n+GXm4LGZjXf3XZY6Ws8FXiuq5kXIDISwuyXbhy880Gaewx89Yyjfjjp06FCPsugypX7oP/30U8wM\nd+/2iMxs4n4dggIhu7geeONar1J0dnZ2u0izoaEhlq3TXbt2MWzYMNra2mhra+Pkk09On6BSKXlb\nCO7eAVwDrAW2AI+6+yYzW2RmFwOY2UwzawG+Diwzs7Dj/BvAOcCVWU4vfcjMXgVeBcYCd5Z1yyKK\naSGE38Kjg7bFthCyBUL0A9WXQAjvSxQOLueSrcsoDh/qQ4cO8cUvfpEtW7YoELKIwz7KJq71KkV/\naSFccMEFHHfccZxyyilMnz6dd955p+K/s6B7Gbj7amB1RtntkdcbSHUlZS73K+BXOdZ5blE1LaPw\nj+GDDz7o8V4YCNHTOottIWTrMipXC2HEiBHs27cv7zMZ2tvbu32baGxspKOjA3ev6dO43n//fZ57\n7jlmz57Nd77zHeDw9Rpx/JZWbeHfRtyemBbXrqxSxD0QjjnmGN577z2WLVvG4MGDGTRoEIMHD2b8\n+PEV/93xublNBWV+uMLphQsX8u1vf7vbe9laCGPGjOGjjz5KT+c7cFWqy+jAgQMMGzaMxsZGHnjg\ngbzzRu9yOnToUCDVssh3ymol7d+/H4Drr7+eL33pS+nyxsbGWH0oa6WaN0AsRj23EOL2tzdw4EDm\nz5/PwoULq/67E3Hrirvvvptp06alp3v79hUGwvHHHw/AzJkzmTdvXp/HEPraZeTurFy5koaGhqzr\nz/Txxx8zZsyY9PSwYcOAww/OqZUwEEaMGNGtPG7f0molbkEQqudAiNvfXldXV4+7HFRLIgLhnHPO\n6XY9QG/CA+add97J8uXLWb9+fbfHPEJtBpXffvttIPsFadnW19ramjUQSn3aW7koEHoX1wNvXOtV\niv4QCNH6VVMiuowyFdJCGDVqFFdccUW6vNZnGd18c+oyjXvvvZeRI0dywgknpN/78MMP6erqoqOj\ng/b2dg4ePMj+/ftj10Lo6OjgwQcfBLIHgsYQ4tVCiIZAvQdCnP72Ojs7a9ZCSFQgrF69mkmTJnU7\nOIe3YQ5Fn0Uc1dfrEPraZfTOO+8watQoZsyY0SPQ/uRP/iTrMtFBqDgEwhNPPMEjjzwCpJ6UFhW3\nftxaidOBN9qajFNQ9VW2QHj11Ve56667AGhpaeH999+vVfVobW1VIFTDhRdeCMDGjRvTZT/96U9Z\nvHhxenrfvn1Az2+w1W4htLa28sQTT/DlL3+ZxYsX09zczHe/+90eYXDnnXcyYsQIGhsb0z8DBw5k\nxIgRXHTRRen5wkB46aWX8v7uSnn66acBeOutt7q1XiD1ody1axcvvvhiLaoWG6+9lrocZ+vWrdxz\nzz1lX//vfvc7nn/+eT7++GO++c1v0tXVRWdnJ52dnenX4b/Ra11eeOGFugmFTz75pFsgHHfccTz7\n7LNs2LAhXXbsscfW7IFSkyZN6nbCRTUlKhCyCZ9dENq7dy9HHnlkjz686HQ1zjI68cQT+fDDD9PT\np512Wrd7MC1fvpyPPvqI6667Lu+6AMKrvK+++uqC5q+UiRMnctxxx/UoHzFiBCtXrmTlypU1qFX8\nvPjiixULx/DLzfLlyzn++OMZMGBA+lqbzNeha6+9tiJ1qZWzzz47/frJJ5/s1hoaOHBg+gtU0iQy\nEKLfsjOv+N27d2/Wh9KX2kII11Vsf2w0DCB1gIgOKEfHNwpx6qmn8txzz6VbQLUyderUrOVr167l\njTfeqHJt4umMM86o2BWpjY2NrFixgquvvpr58+enx3RyWbduHV/5ylcYP348P//5zytSp1qYNevw\nnXIaGxuzfuaTKJGBEJUZCPv27csbCPlO+4yOIRx11FHA4RBpbGzk448/LqqOQ4cO7fO1A2bG7Nmz\n+7SOSjrhhBO6DZRL5cydO5clS5b0etffUNiaPfXUU7t1QUp9SmQglNJCiHYZ5bttRDQwwiAJA2Hi\nxIns2LGjx8BWbyp9/xJJlvHjx7N9+/aC5g0/H7W8mFGqJxHXIfQmWyCMHDmyx3zRFkIhdxoNhUEQ\ndhNNmDCBrq4udu/eXXAdFQhSK+HnI/OsO6lPiQyEarYQwgHoMBjGjh0LUFRfvgJBakUthGRRIJQw\nhlBMIGS2EMKzF/LdvjpKgSC1ohZCsiRyDCFq06ZN3HDDDcyYMYPW1lZaW1uzdhkV00KIDip3dnZy\n2223sXTpUgCGDx8OKBCkf/jTP/1TAGbMmFHjmkg1JDIQoqd9jh07Nn2wDk2ZMqXHMn1pISxZsiQd\nEgoE6U/+4i/+gvXr1zNz5sxaV0WqIJFdRmEgnH766ezZs4c333yTdevWcckll/Dcc89x1VVX9Vgm\n2kLYt28fu3btynqB2e9///v0oPMXvvAFOjs701flnnbaaZx33nlAcYEQfTaDSLXNmjUrds9nkMpI\nZAsh7NfsaJJCAAAH1UlEQVQPv/WH58Cff/75OZeJthAeeughHnroIW6//Xa++c1v0tbWxoknnsj3\nvvc9li1bBqTO2/7iF7/IG2+8QXt7O9/73ve466672LJlC9D9+ciQOnPpn/7pn9i/f3+P+/yohSAi\n1VBQIJjZHOAfgAbg5+7+04z3zwHuAs4ALos+P9nM5gM/DibvdPdfBOVnAg8CQ0g9je06r9LNUsJA\nKOYWs9m+pS9atIhFixZlnf+UU05hyJAh6UviJ06cyIABA9Jna2S2EJ5++mmuv/76rOuaNGlSwfUU\nESlV3kAwswbgHuB8oAXYYGar3H1zZLYdwJXAjRnLjgF+AjQBDrwULNsK3At8G1hPKhDmAGv6ukGF\nKCUQJk48/ITQ1atXp2+INXToUP7u7/6O119/nbFjx/LVr36VjRs3cuWVV3LmmWdywgknMGrUKObM\nmQMcPltj7dq1nHTSSQwcOJBBgwbx7//+7+n1Dx8+nNdff52jjz66x3MNREQqpZAWwixgm7tvBzCz\nFcAlQDoQ3P2d4L3Mm/R8BXjS3T8O3n8SmGNmzwIj3P2FoPyXwFyqFAjhGEIxgXDssccCqTumhndN\nPemkk4DUfYduuukmHnzwQb761a92W27BggXdpkeOHMmQIUN4+OGHefjhh7P+riVLljBhwgTg8E3p\nREQqrZBAmAC8G5luAf6swPVnW3ZC8NOSpbwHM1sILITDp8D1VeYYQiGOPvpo1qxZk/Vsi+9///tc\nd911Ba1vyJAhvPXWW2zZsoVDhw7R3t7OoUOHuPTSS4FUWGkAT0RqIfaDyu5+H3AfQFNTU1nGGEpp\nIQDpbp9sigmX8ePHd3t4DcCPf/xjVq5cqTAQkZop5Ci2E4iOak4MygqRa9mdwetS1tlnpbQQKu2O\nO+5g8+bN+WcUEamQQo6IG4CpZjbFzAYBlwGrClz/WuACMxttZqOBC4C17r4L2G9mZ1nqK/G3gN+U\nUP+SlDKoLCJS7/IGgrt3ANeQOrhvAR51901mtsjMLgYws5lm1gJ8HVhmZpuCZT8G7iAVKhuAReEA\nM3A18HNgG/AWVRpQhsMtg6Q+FUlEJBvrT89JbWpq8ubm5j6vp6uri7/927/luuuuy/mAehGRemFm\nL7l7U775Yj+oXAkDBgxg8eLFta6GiEisxGdUVUREakqBICIigAJBREQCCgQREQEUCCIiElAgiIgI\noEAQEZGAAkFERIB+dqWyme0B/rPExccCH5axOv2BtjkZtM3J0JdtPtbd8z5cpV8FQl+YWXMhl27X\nE21zMmibk6Ea26wuIxERARQIIiISSFIg3FfrCtSAtjkZtM3JUPFtTswYgoiI9C5JLQQREelFIgLB\nzOaY2VYz22Zmt9S6PuVgZpPM7Bkz22xmm8zsuqB8jJk9aWZvBv+ODsrNzO4O/g82mtkXarsFpTOz\nBjN72cx+G0xPMbP1wbY9EjzqFTMbHExvC96fXMt6l8rMRpnZY2b2upltMbOz630/m9n3g7/r18zs\nYTM7ot72s5ndb2a7zey1SFnR+9XM5gfzv2lm8/tSp7oPBDNrAO4BLgSmAZeb2bTa1qosOoAfuPs0\n4Czgu8F23QI85e5TgaeCaUht/9TgZyFwb/WrXDbXkXqca+jvgaXufgLQCiwIyhcArUH50mC+/ugf\ngN+5+8nA50lte93uZzObAFwLNLn7aUADqWe519t+fhCYk1FW1H41szHAT4A/A2YBPwlDpCTuXtc/\nwNnA2sj0rcCtta5XBbbzN8D5wFZgfFA2HtgavF4GXB6ZPz1ff/oBJgYflHOB3wJG6mKdxsz9Teo5\n4GcHrxuD+azW21Dk9o4E3s6sdz3vZ2AC8C4wJthvvwW+Uo/7GZgMvFbqfgUuB5ZFyrvNV+xP3bcQ\nOPzHFWoJyupG0ESeAawHjnb3XcFb7wNHB6/r5f/hLuCHQFcwfRSw1907gunodqW3OXh/XzB/fzIF\n2AM8EHST/dzMhlHH+9nddwL/C9gB7CK1316ivvdzqNj9Wtb9nYRAqGtmNhxYCVzv7vuj73nqK0Pd\nnEZmZv8N2O3uL9W6LlXUCHwBuNfdZwCfcrgbAajL/TwauIRUGB4DDKNn10rdq8V+TUIg7AQmRaYn\nBmX9npkNJBUGD7n7vwbFH5jZ+OD98cDuoLwe/h9mAxeb2TvAClLdRv8AjDKzxmCe6Haltzl4fyTw\nUTUrXAYtQIu7rw+mHyMVEPW8n88D3nb3Pe7eDvwrqX1fz/s5VOx+Lev+TkIgbACmBmcoDCI1OLWq\nxnXqMzMz4F+ALe7+vyNvrQLCMw3mkxpbCMu/FZytcBawL9I07Rfc/VZ3n+juk0ntx6fd/b8DzwCX\nBrNlbnP4f3FpMH+/+ibt7u8D75rZSUHRfwU2U8f7mVRX0VlmNjT4Ow+3uW73c0Sx+3UtcIGZjQ5a\nVhcEZaWp9aBKlQZuLgLeAN4Cbqt1fcq0Tf+FVHNyI/BK8HMRqb7Tp4A3gf8HjAnmN1JnW70FvErq\nDI6ab0cftv/LwG+D18cBLwLbgF8Dg4PyI4LpbcH7x9W63iVu63SgOdjX/xcYXe/7GfifwOvAa8By\nYHC97WfgYVJjJO2kWoILStmvwFXBtm8D/rovddKVyiIiAiSjy0hERAqgQBAREUCBICIiAQWCiIgA\nCgQREQkoEEREBFAgiIhIQIEgIiIA/H8a4C+/I7Dr9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1063769e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(accuracy_list, color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network.set_flag(weight_decay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "for i in range(1000) : \n",
    "    x_batch, t_batch = get_mini_batch(x_train, y_train, i, batch_size)\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    params = network.params\n",
    "    network.params = optimizer.update(params, grads)\n",
    "    accuracy_list.append(network.accuracy(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAE9RJREFUeJzt3X2QXXV9x/H3lzzwqPIUIxIwcUypGYaKXWICFTtWIEgH\nBgcYqB2DxaGOzdQ+OB0cHZjidKbVtopTxoFa66iVB4HaQGNjShmrMxWy8QFJIrJEDJsGCChUnrIu\n+faPe3a52U24Z+/ezU1+5/2auZN7fufcu7+Tc36f+72/c+9uZCaSpGY4qN8dkCTtO4a+JDWIoS9J\nDWLoS1KDGPqS1CCGviQ1iKEvSQ1i6EtSgxj6ktQgs/vdgYmOPfbYXLhwYb+7IUkHlA0bNjyZmfM6\nbbffhf7ChQsZHBzsdzck6YASET+rs53TO5LUIIa+JDWIoS9JDWLoS1KDGPqS1CCGviQ1iKEvSQ1i\n6Evaq23btnHnnXf2uxvqof3uy1mS9h+nn346W7duxb+lXQ4rfUl7tXXr1n53QT1m6EtSgxj6ktQg\nhr4kNYihL0kNYuhLUoMY+pI68iOb5TD0JalBDH1JahBDX1JHTu+Uw9CXpAapFfoRsSIiHoyIoYi4\nag/r/ywiNkXE/RFxd0S8oW3dyoh4qLqt7GXnJUlT0zH0I2IWcD1wLrAEuCwilkzY7PvAQGaeAtwG\nfLJ67NHANcDbgKXANRFxVO+6L2lfcHqnHHUq/aXAUGZuycwR4GbggvYNMvOezHy+WvwusKC6fw6w\nLjN/npm/ANYBK3rTdUnSVNUJ/eOBR9uWh6u2vbkC+EaXj5W0H7LSL0dPf59+RPw+MAC8Y4qPuxK4\nEuDEE0/sZZckSW3qVPrbgBPalhdUbbuJiHcBHwPOz8ydU3lsZt6YmQOZOTBv3ry6fZckTVGd0F8P\nLI6IRRExF7gUWN2+QUScCtxAK/CfaFu1Fjg7Io6qLuCeXbVJOoA4vVOOjtM7mTkaEatohfUs4AuZ\nuTEirgUGM3M18CngCOBrEQGwNTPPz8yfR8QnaL1wAFybmT+fkT2RJHUU+9sr+MDAQA4ODva7G5KA\nqohj586dzJ07t8+90SuJiA2ZOdBpO7+RK0kNYuhLUoMY+pI62t+mgdU9Q1+SGqTY0H/yySeJCO64\n445+d0U64Fnpl6PY0H/ggQcAuO666/rcE0nafxQb+mPGPnImSWpA6EuaPqd3ymHoS1KDFBv6ViZS\n7zieylFs6I9xTl+SXlZ86EuSXmboS+rI6Z1yFBv6nqSSNFmxoT/GOX1JelnxoS9p+nznXI7iQ390\ndJQXX3yx392QpP1CsaE/Vpl8+9vf5tBDD+1zb6QDm5V+OYoNfUnSZIa+JDWIoS+pI6d3ylFs6HuS\nStJkxYa+pN6xiCqHoS9JDWLoS1KDFBv6vh2VesfxVI5iQ1+SNJmhL6kjK/1yGPqS1CDFhr6ViSRN\nVmzoS+odi6hyGPqS1CCGvqSOrPTLUSv0I2JFRDwYEUMRcdUe1p8ZEd+LiNGIuGjCuk9GxMaI2BwR\nnw3/fqEk9U3H0I+IWcD1wLnAEuCyiFgyYbOtwOXAVyc89nTgDOAU4GTgNOAd0+51DVYmkjTZ7Brb\nLAWGMnMLQETcDFwAbBrbIDMfqdbtmvDYBA4B5gIBzAEen3avJe1TFlHlqDO9czzwaNvycNXWUWb+\nD3APsL26rc3MzVPtpCSpN2b0Qm5EvAl4M7CA1gvFOyPi7XvY7sqIGIyIwR07dsxklySp0eqE/jbg\nhLblBVVbHRcC383MZzPzWeAbwPKJG2XmjZk5kJkD8+bNq/nUr8y3o1LvOJ7KUSf01wOLI2JRRMwF\nLgVW13z+rcA7ImJ2RMyhdRHX6R1J6pOOoZ+Zo8AqYC2twL41MzdGxLURcT5ARJwWEcPAxcANEbGx\nevhtwMPAj4AfAj/MzDtnYD8kzSAr/XLU+fQOmbkGWDOh7eq2++tpTftMfNxLwB9Os4+SpB4p9hu5\nViaSNFmxoS+pdyyiymHoS1KDGPqSOrLSL0exoe9JKkmTGfqS1CCGvqSOHE/lMPQlqUEMfUkdOZ7K\nYehLUoMY+pLUIIa+pI4cT+Uw9CWpQQx9SR05nsph6EtSgxj6ktQghr6kjhxP5TD0JalBDH1JahBD\nX1JHjqdyGPqS1CCGvqSOHE/lMPQlqUEMfUlqEENfUkeOp3IY+pLUIIa+pI4cT+Uw9CWpQRoT+r4I\nSFKDQl9S9xxP5WhM6HvSSlKDQl9S9xxP5WhM6HvSSlLN0I+IFRHxYEQMRcRVe1h/ZkR8LyJGI+Ki\nCetOjIhvRsTmiNgUEQt70/VXZshL0mQdQz8iZgHXA+cCS4DLImLJhM22ApcDX93DU3wJ+FRmvhlY\nCjwxnQ7XZaUv9Y7jpxyza2yzFBjKzC0AEXEzcAGwaWyDzHykWrer/YHVi8PszFxXbfdsb7rdmSep\nJE1WZ3rneODRtuXhqq2OXwOejog7IuL7EfGp6p3DjLPSl3rH8VOOmb6QOxt4O/AR4DTgjbSmgXYT\nEVdGxGBEDO7YsaMnP9iTVJImqxP624AT2pYXVG11DAM/yMwtmTkKfB1468SNMvPGzBzIzIF58+bV\nfOpXZqUvSZPVCf31wOKIWBQRc4FLgdU1n389cGREjCX5O2m7FjCTDHmpdxxP5egY+lWFvgpYC2wG\nbs3MjRFxbUScDxARp0XEMHAxcENEbKwe+xKtqZ27I+JHQAD/ODO7Mqnfr7gsSU1U59M7ZOYaYM2E\ntqvb7q+nNe2zp8euA06ZRh+7YshL0mR+I1dSR46fcjQm9CVJDQp9XwSk7jl+ytGY0JckNSj0fRGQ\npAaFvqTuOZ7K0ZjQ96SVpAaFvqTuOZ7K0ZjQ96SVpAaFviSpQaHvi4DUPcdPORoT+pKkBoW+LwJS\n9xw/5WhM6EuSGhT6vghIUoNCX1L3HE/laEzoe9JKUoNCX5LUoND3RUDqnuOnHI0JfUmSoS+pBsdT\nORoT+p60ktSg0JckNSj0fRGQuuf4KUdjQl+S1IDQ//jHP77bsqSpc/yUo+jQP+SQQ5g/f36/uyJJ\n+42iQz8idluWpKYrPvTbg19SdyyaylF86LcvS1LTFR/6VvrS9Fk0laP40G9flqSmKz70rfQl6WW1\nQj8iVkTEgxExFBFX7WH9mRHxvYgYjYiL9rD+1RExHBH/0ItO12GlL3Xn8ccf57777tutzfFTjtmd\nNoiIWcD1wFnAMLA+IlZn5qa2zbYClwMf2cvTfAL47+l1dWqs9KXunHrqqWzfvt2gL1SdSn8pMJSZ\nWzJzBLgZuKB9g8x8JDPvB3ZNfHBE/CYwH/hmD/pbm5W+1J3t27dPanP8lKNO6B8PPNq2PFy1dRQR\nBwF/x97fAcwYK31JmmymL+R+CFiTmcOvtFFEXBkRgxExuGPHjp78YCt9SZqs45w+sA04oW15QdVW\nx3Lg7RHxIeAIYG5EPJuZu10MzswbgRsBBgYGepLOVvpS71g0laNO6K8HFkfEIlphfynwe3WePDPf\nO3Y/Ii4HBiYG/kyx0pekyTpO72TmKLAKWAtsBm7NzI0RcW1EnA8QEadFxDBwMXBDRGycyU7XYaUv\nTY+FUpnqVPpk5hpgzYS2q9vur6c17fNKz/FF4ItT7mGXrPSl6WkfM46fcviNXEl7ZNCXqfjQb1+W\nVJ+VfpmKD30rfak7u3ZN+q6lClB86LcvS6rP0C9T8aFvpS9156WXXhq/b9FUjuJDv31ZUn3toa9y\nFB/6VvpSd6z0y1R86LcvS6rPOf0yNSb0JU2N0ztlKj70x4LfSl+amvZK3/FTjuJDX1J3rPTLVHzo\nW+lL3bHSL1PxoS+pO1b6ZSo+9K30pe4Y+mUqPvQldcfP6Zep+NC30pfqGx0dHb/v5/TLVHzoS6rv\nueeeG79vpV+m4kPfSl+q79lnnx2/b6VfpuJDX1J97aHvhdwyFR/6VvpSfSMjI+P3/Zx+mYoPfUn1\ntV/ItdIvU/Ghb6Uv1eend8pXfOhLqm9vlb5FUzmKD30rfak+p3fKV3zoS6qvPfR37tw5ft+iqRzF\nh76VvlRfe3W/atWqPvZEM6X40JdUX3ul3/7tXJWj+NC30pfqaw/9kZERZs2aBTh+SlJ86Euqb2Lo\nz5kzp4+90UwoPvSt9KX69hb6jp9yFB/6kuqbGPqzZ8/uY280E4oPfSt9qb720B8dHXV6p0DFh76k\n+tpDH3B6p0DFvHcbGRnhW9/6FgCPPfYY69atY/ny5Vb60hRMDH2nd8pT64hGxArgOmAW8PnM/OsJ\n688EPgOcAlyambdV7W8BPge8GngJ+KvMvKV33X/ZM888w9lnn71b24UXXjgTP0oq1sRfvWClX56O\noR8Rs4DrgbOAYWB9RKzOzE1tm20FLgc+MuHhzwPvy8yHIuL1wIaIWJuZT/ek922OPPJIvvOd74wv\nn3TSSRx77LHcfvvtgCetVMfepndUjjqV/lJgKDO3AETEzcAFwHjoZ+Yj1brdfhdrZv6k7f7/RsQT\nwDyg56E/Z84czjjjjF4/rdQohn756lzIPR54tG15uGqbkohYCswFHt7DuisjYjAiBnfs2DHVp+70\ncwErfamOvc3pO37KsU8+vRMRxwFfBt6fmZP+MkNm3piZA5k5MG/evH3RJUl74IXc8tUJ/W3ACW3L\nC6q2WiLi1cC/Ax/LzO9OrXvT58c2pfra/0YueCG3RHVCfz2wOCIWRcRc4FJgdZ0nr7b/V+BLY5/o\n6RdPWqmzvYW+ytEx9DNzFFgFrAU2A7dm5saIuDYizgeIiNMiYhi4GLghIjZWD78EOBO4PCJ+UN3e\nMiN7shdW+lJ97X84BQz9EtWasMvMNcCaCW1Xt91fT2vaZ+LjvgJ8ZZp97AkrfamziaHvhdzyFPtr\nGMZY6Uv1TZze8UJueRpzRK1UpM527tzJ4YcfznnnnccLL7zAeeedx5133tnvbqmHig99K32pvpGR\nEV73utdxyy2t35Zy7733AhZNJSl+emeMJ63U2c6dO5k7d+74skVTeYoPfU9aqb6dO3dy8MEHT2q3\naCpH8aE/xpNW6mxkZGS3Sl/lcU5f2ovM5Pnnnx9fHhoa4pe//CXLli0r6lMtL7zwArt27Rq/317p\nO37KU86Z28Ell1zCoYce2u9u6ADy1FNP8fjjj09qnz9/Psccc0wfetR7L774Ilu2bNmt7Zxzzpm0\n3Qc/+EFe9apX7atuNdYpp5zCTTfdNKM/o/jQX7ZsGStXruS5557rd1d0gDnooINYsmQJhx12GABH\nHHEEc+bMYd26deOVcQne85738NrXvnZ8+ayzzhq/f/LJJ/OBD3yAp5/u+W9D1x4sWrRoxn9G7G9z\n3QMDAzk4ONjvbkjSASUiNmTmQKftGnMhV5Jk6EtSoxj6ktQghr4kNYihL0kNYuhLUoMY+pLUIIa+\nJDXIfvflrIjYAfxsGk9xLPBkj7pzoHCfy9e0/QX3earekJnzOm2034X+dEXEYJ1vpZXEfS5f0/YX\n3OeZ4vSOJDWIoS9JDVJi6N/Y7w70gftcvqbtL7jPM6K4OX1J0t6VWOlLkvaimNCPiBUR8WBEDEXE\nVf3uT69ExAkRcU9EbIqIjRHx4ar96IhYFxEPVf8eVbVHRHy2+n+4PyLe2t896F5EzIqI70fEXdXy\nooi4t9q3WyJibtV+cLU8VK1f2M9+dysijoyI2yLixxGxOSKWl36cI+JPq/P6gYi4KSIOKe04R8QX\nIuKJiHigrW3KxzUiVlbbPxQRK7vtTxGhHxGzgOuBc4ElwGURsaS/veqZUeDPM3MJsAz4o2rfrgLu\nzszFwN3VMrT+DxZXtyuBz+37LvfMh4HNbct/A3w6M98E/AK4omq/AvhF1f7parsD0XXAf2TmrwO/\nQWvfiz3OEXE88MfAQGaeDMwCLqW84/xFYMWEtikd14g4GrgGeBuwFLhm7IViyjLzgL8By4G1bcsf\nBT7a737N0L7+G3AW8CBwXNV2HPBgdf8G4LK27ce3O5BuwIJqMLwTuAsIWl9amT3xmANrgeXV/dnV\ndtHvfZji/r4G+OnEfpd8nIHjgUeBo6vjdhdwTonHGVgIPNDtcQUuA25oa99tu6nciqj0efnkGTNc\ntRWlejt7KnAvMD8zt1erHgPmV/dL+b/4DPAXwNgfoz0GeDozR6vl9v0a3+dq/TPV9geSRcAO4J+r\nKa3PR8ThFHycM3Mb8LfAVmA7reO2gbKP85ipHteeHe9SQr94EXEEcDvwJ5n5f+3rsvXSX8zHsCLi\nd4EnMnNDv/uyD80G3gp8LjNPBZ7j5bf8QJHH+SjgAloveK8HDmfyNEjx9vVxLSX0twEntC0vqNqK\nEBFzaAX+v2TmHVXz4xFxXLX+OOCJqr2E/4szgPMj4hHgZlpTPNcBR0bE7Gqb9v0a3+dq/WuAp/Zl\nh3tgGBjOzHur5dtovQiUfJzfBfw0M3dk5q+AO2gd+5KP85ipHteeHe9SQn89sLi66j+X1sWg1X3u\nU09ERAD/BGzOzL9vW7UaGLuCv5LWXP9Y+/uqTwEsA55pext5QMjMj2bmgsxcSOtY/ldmvhe4B7io\n2mziPo/9X1xUbX9AVcSZ+RjwaEScVDX9DrCJgo8zrWmdZRFxWHWej+1zsce5zVSP61rg7Ig4qnqH\ndHbVNnX9vsDRwwsl7wZ+AjwMfKzf/enhfv0Wrbd+9wM/qG7vpjWXeTfwEPCfwNHV9kHrk0wPAz+i\n9cmIvu/HNPb/t4G7qvtvBO4DhoCvAQdX7YdUy0PV+jf2u99d7utbgMHqWH8dOKr04wz8JfBj4AHg\ny8DBpR1n4CZa1yx+Resd3RXdHFfgD6p9HwLe321//EauJDVIKdM7kqQaDH1JahBDX5IaxNCXpAYx\n9CWpQQx9SWoQQ1+SGsTQl6QG+X9gQXEy9wdjkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106376ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(accuracy_list, color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dropout : \n",
    "    def __init__(self, dropout_ratio = 0.5) : \n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "        \n",
    "    def train_forward(self, x) : \n",
    "        self.mask = np.random.rand(*x.shape) > self.dropout_ratio #x와 shape가 같고 0~1 사이 실수를 원소로 갖는 ndarray를 만든다.\n",
    "                                                                    #dropout_ratio값 보다 큰 곳의 위치 정보를 self.mask에 저장한다.\n",
    "        return x * self.mask\n",
    "    \n",
    "    def test_forward(self, x) : \n",
    "        return x * (1.0 - self.dropout_ratio)\n",
    "        \n",
    "    def backward(self, dout) : \n",
    "        return dout * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = TwoLayerNet(input_size=x_train.shape[1], hidden_size=50, output_size=10)\n",
    "optimizer = Momentum()\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.set_flag(weight_decay=False, drop_out=True)\n",
    "network.set_train_flag(train_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-1c3d6dc51fe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maccuracy_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-62f9d74de4e1>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, params, grads)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "for i in range(1000) : \n",
    "    x_batch, t_batch = get_mini_batch(x_train, y_train, i, batch_size)\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    params = network.params\n",
    "    network.params = optimizer.update(params, grads)\n",
    "    network.set_train_flag(train_flag=False)\n",
    "    accuracy_list.append(network.accuracy(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107ed1b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(accuracy_list, color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
